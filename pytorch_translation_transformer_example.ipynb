{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "source": [
        "%matplotlib inline"
      ],
      "outputs": [],
      "metadata": {
        "collapsed": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Language Translation with nn.Transformer and torchtext\n",
        "======================================================\n",
        "\n",
        "This tutorial shows, how to train a translation model from scratch using\n",
        "Transformer. We will be using `Multi30k <http://www.statmt.org/wmt16/multimodal-task.html#task1>`__ \n",
        "dataset to train a German to English translation model.\n",
        "\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Sourcing and Processing\n",
        "----------------------------\n",
        "\n",
        "`torchtext library <https://pytorch.org/text/stable/>`__ has utilities for creating datasets that can be easily\n",
        "iterated through for the purposes of creating a language translation\n",
        "model. In this example, we show how to use torchtext's inbuilt datasets, \n",
        "tokenize a raw text sentence, build vocabulary, and numericalize tokens into tensor. We will use\n",
        "`Multi30k dataset from torchtext library <https://pytorch.org/text/stable/datasets.html#multi30k>`__\n",
        "that yields a pair of source-target raw sentences. \n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "data_dir='./data/news-commentary-v16.en-zh.tsv'\n",
        "seed=520\n",
        "\n",
        "data = pd.read_csv(data_dir, sep='\\t', encoding='utf-8', names=['src', 'tgt'], nrows=200000)\n",
        "data = data.dropna(axis=0).reset_index(drop=True)\n",
        "train_data=data.sample(frac=0.8,random_state=seed)\n",
        "val_data=data.drop(train_data.index).reset_index(drop=True)\n",
        "train_data=train_data.reset_index(drop=True)\n",
        "data"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                      src  \\\n",
              "0                                           1929 or 1989?   \n",
              "1       PARIS – As the economic crisis deepens and wid...   \n",
              "2       At the start of the crisis, many people likene...   \n",
              "3       Today, the mood is much grimmer, with referenc...   \n",
              "4       The tendency is either excessive restraint (Eu...   \n",
              "...                                                   ...   \n",
              "194690  In the near future, drugs may even be repositi...   \n",
              "194691  New technologies like AI and augmented reality...   \n",
              "194692  To realize this future, however, systematic re...   \n",
              "194693  Fortunately, there are strong economic incenti...   \n",
              "194694  If they do, we may find ourselves on the cusp ...   \n",
              "\n",
              "                                                      tgt  \n",
              "0                                           1929年还是1989年?  \n",
              "1       巴黎-随着经济危机不断加深和蔓延，整个世界一直在寻找历史上的类似事件希望有助于我们了解目前正...  \n",
              "2       一开始，很多人把这次危机比作1982年或1973年所发生的情况，这样得类比是令人宽心的，因为...  \n",
              "3       如今人们的心情却是沉重多了，许多人开始把这次危机与1929年和1931年相比，即使一些国家政...  \n",
              "4                  目前的趋势是，要么是过度的克制（欧洲 ） ， 要么是努力的扩展（美国 ） 。  \n",
              "...                                                   ...  \n",
              "194690                     不久之后，药物甚至可以实时再利用，对准每一位患者的独特需要。  \n",
              "194691                     人工智能和增强现实等新科技将有助于医生发现疑难杂症的新疗法。  \n",
              "194692                   但要实现这一未来，各大制药企业都必须将系统性再利用纳入商业模式。  \n",
              "194693                                幸运的是，公司有强力的经济激励这样做。  \n",
              "194694  如此，我们或许有新的发现：利用生物联动性（biological interconnected...  \n",
              "\n",
              "[194695 rows x 2 columns]"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>src</th>\n",
              "      <th>tgt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1929 or 1989?</td>\n",
              "      <td>1929年还是1989年?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>PARIS – As the economic crisis deepens and wid...</td>\n",
              "      <td>巴黎-随着经济危机不断加深和蔓延，整个世界一直在寻找历史上的类似事件希望有助于我们了解目前正...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>At the start of the crisis, many people likene...</td>\n",
              "      <td>一开始，很多人把这次危机比作1982年或1973年所发生的情况，这样得类比是令人宽心的，因为...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Today, the mood is much grimmer, with referenc...</td>\n",
              "      <td>如今人们的心情却是沉重多了，许多人开始把这次危机与1929年和1931年相比，即使一些国家政...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The tendency is either excessive restraint (Eu...</td>\n",
              "      <td>目前的趋势是，要么是过度的克制（欧洲 ） ， 要么是努力的扩展（美国 ） 。</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>194690</th>\n",
              "      <td>In the near future, drugs may even be repositi...</td>\n",
              "      <td>不久之后，药物甚至可以实时再利用，对准每一位患者的独特需要。</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>194691</th>\n",
              "      <td>New technologies like AI and augmented reality...</td>\n",
              "      <td>人工智能和增强现实等新科技将有助于医生发现疑难杂症的新疗法。</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>194692</th>\n",
              "      <td>To realize this future, however, systematic re...</td>\n",
              "      <td>但要实现这一未来，各大制药企业都必须将系统性再利用纳入商业模式。</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>194693</th>\n",
              "      <td>Fortunately, there are strong economic incenti...</td>\n",
              "      <td>幸运的是，公司有强力的经济激励这样做。</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>194694</th>\n",
              "      <td>If they do, we may find ourselves on the cusp ...</td>\n",
              "      <td>如此，我们或许有新的发现：利用生物联动性（biological interconnected...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>194695 rows × 2 columns</p>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "source": [
        "from torch.utils.data import Dataset\n",
        "class MyDataset(Dataset):\n",
        "    def __init__(self,data) -> None:\n",
        "        super(MyDataset).__init__()\n",
        "        \n",
        "        self.data=data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.data['src'][index],self.data['tgt'][index]"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "source": [
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "#from torchtext.datasets import Multi30k\n",
        "from typing import Iterable, List\n",
        "import os\n",
        "import torch\n",
        "\n",
        "\n",
        "SRC_LANGUAGE = 'en'\n",
        "TGT_LANGUAGE = 'zh'\n",
        "# Place-holders\n",
        "token_transform = {}\n",
        "vocab_transform = {}\n",
        "\n",
        "\n",
        "# Create source and target language tokenizer. Make sure to install the dependencies.\n",
        "# pip install -U spacy\n",
        "# python -m spacy download en_core_web_sm\n",
        "# python -m spacy download de_core_news_sm\n",
        "\n",
        "token_transform[SRC_LANGUAGE] = get_tokenizer('spacy', language='en_core_web_sm')\n",
        "token_transform[TGT_LANGUAGE] = get_tokenizer('spacy', language='zh_core_web_sm')\n",
        "\n",
        "# helper function to yield list of tokens\n",
        "def yield_tokens(data_iter: Iterable, language: str) -> List[str]:\n",
        "    language_index = {SRC_LANGUAGE: 0, TGT_LANGUAGE: 1}\n",
        "\n",
        "    for i in range(len(data_iter)):\n",
        "        yield token_transform[language](data_iter[i][language_index[language]])\n",
        "\n",
        "# Define special symbols and indices\n",
        "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
        "# Make sure the tokens are in order of their indices to properly insert them in vocab\n",
        "special_symbols = ['<unk>', '<pad>', '<bos>', '<eos>']\n",
        " \n",
        "data_iter=MyDataset(data)\n",
        "vocab_transform_dir='./checkpoints/pytorch_vocab.pkl'\n",
        "\n",
        "if not os.path.exists(vocab_transform_dir):\n",
        "    for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
        "        # Create torchtext's Vocab object \n",
        "        vocab_transform[ln] = build_vocab_from_iterator(yield_tokens(data_iter, ln),\n",
        "                                                        min_freq=1,\n",
        "                                                        specials=special_symbols,\n",
        "                                                        special_first=True)\n",
        "\n",
        "    # Set UNK_IDX as the default index. This index is returned when the token is not found. \n",
        "    # If not set, it throws RuntimeError when the queried token is not found in the Vocabulary. \n",
        "    for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
        "        vocab_transform[ln].set_default_index(UNK_IDX)\n",
        "    print('save vocab')\n",
        "    torch.save(vocab_transform,vocab_transform_dir)\n",
        "else:\n",
        "    print('load vocab')\n",
        "    vocab_transform=torch.load(vocab_transform_dir)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "load vocab\n"
          ]
        }
      ],
      "metadata": {
        "collapsed": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Seq2Seq Network using Transformer\n",
        "---------------------------------\n",
        "\n",
        "Transformer is a Seq2Seq model introduced in `“Attention is all you\n",
        "need” <https://papers.nips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf>`__\n",
        "paper for solving machine translation tasks. \n",
        "Below, we will create a Seq2Seq network that uses Transformer. The network\n",
        "consists of three parts. First part is the embedding layer. This layer converts tensor of input indices\n",
        "into corresponding tensor of input embeddings. These embedding are further augmented with positional\n",
        "encodings to provide position information of input tokens to the model. The second part is the \n",
        "actual `Transformer <https://pytorch.org/docs/stable/generated/torch.nn.Transformer.html>`__ model. \n",
        "Finally, the output of Transformer model is passed through linear layer\n",
        "that give un-normalized probabilities for each token in the target language. \n",
        "\n",
        "\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "source": [
        "from torch import Tensor\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import Transformer\n",
        "import math\n",
        "\n",
        "# helper Module that adds positional encoding to the token embedding to introduce a notion of word order.\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self,\n",
        "                 emb_size: int,\n",
        "                 dropout: float,\n",
        "                 maxlen: int = 5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        den = torch.exp(- torch.arange(0, emb_size, 2)* math.log(10000) / emb_size)\n",
        "        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n",
        "        pos_embedding = torch.zeros((maxlen, emb_size))\n",
        "        pos_embedding[:, 0::2] = torch.sin(pos * den)\n",
        "        pos_embedding[:, 1::2] = torch.cos(pos * den)\n",
        "        pos_embedding = pos_embedding.unsqueeze(-2)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.register_buffer('pos_embedding', pos_embedding)\n",
        "\n",
        "    def forward(self, token_embedding: Tensor):\n",
        "        return self.dropout(token_embedding + self.pos_embedding[:token_embedding.size(0), :])\n",
        "\n",
        "# helper Module to convert tensor of input indices into corresponding tensor of token embeddings\n",
        "class TokenEmbedding(nn.Module):\n",
        "    def __init__(self, vocab_size: int, emb_size):\n",
        "        super(TokenEmbedding, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, emb_size)\n",
        "        self.emb_size = emb_size\n",
        "\n",
        "    def forward(self, tokens: Tensor):\n",
        "        return self.embedding(tokens.long()) * math.sqrt(self.emb_size)\n",
        "\n",
        "# Seq2Seq Network \n",
        "class Seq2SeqTransformer(nn.Module):\n",
        "    def __init__(self,\n",
        "                 num_encoder_layers: int,\n",
        "                 num_decoder_layers: int,\n",
        "                 emb_size: int,\n",
        "                 nhead: int,\n",
        "                 src_vocab_size: int,\n",
        "                 tgt_vocab_size: int,\n",
        "                 dim_feedforward: int = 512,\n",
        "                 dropout: float = 0.1):\n",
        "        super(Seq2SeqTransformer, self).__init__()\n",
        "        self.transformer = Transformer(d_model=emb_size,\n",
        "                                       nhead=nhead,\n",
        "                                       num_encoder_layers=num_encoder_layers,\n",
        "                                       num_decoder_layers=num_decoder_layers,\n",
        "                                       dim_feedforward=dim_feedforward,\n",
        "                                       dropout=dropout)\n",
        "        self.generator = nn.Linear(emb_size, tgt_vocab_size)\n",
        "        self.src_tok_emb = TokenEmbedding(src_vocab_size, emb_size)\n",
        "        self.tgt_tok_emb = TokenEmbedding(tgt_vocab_size, emb_size)\n",
        "        self.positional_encoding = PositionalEncoding(\n",
        "            emb_size, dropout=dropout)\n",
        "\n",
        "    def forward(self,\n",
        "                src: Tensor,\n",
        "                trg: Tensor,\n",
        "                src_mask: Tensor,\n",
        "                tgt_mask: Tensor,\n",
        "                src_padding_mask: Tensor,\n",
        "                tgt_padding_mask: Tensor,\n",
        "                memory_key_padding_mask: Tensor):\n",
        "        src_emb = self.positional_encoding(self.src_tok_emb(src))\n",
        "        tgt_emb = self.positional_encoding(self.tgt_tok_emb(trg))\n",
        "        outs = self.transformer(src_emb, tgt_emb, src_mask, tgt_mask, None, \n",
        "                                src_padding_mask, tgt_padding_mask, memory_key_padding_mask)\n",
        "        return self.generator(outs)\n",
        "\n",
        "    def encode(self, src: Tensor, src_mask: Tensor):\n",
        "        return self.transformer.encoder(self.positional_encoding(self.src_tok_emb(src)), src_mask)\n",
        "\n",
        "    def decode(self, tgt: Tensor, memory: Tensor, tgt_mask: Tensor):\n",
        "        return self.transformer.decoder(self.positional_encoding(self.tgt_tok_emb(tgt)), memory, tgt_mask)\n",
        "\n",
        "    def predict(self, src, tgt):\n",
        "        device=src.device\n",
        "        num_tokens=src.shape[0]\n",
        "        src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool).to(device)\n",
        "        memory=self.encode(src,src_mask)\n",
        "        #print(memory.shape)\n",
        "        tgt_mask = (generate_square_subsequent_mask(tgt.size(0)).type(torch.bool)).to(device)\n",
        "        out = self.decode(tgt, memory, tgt_mask)\n",
        "        #print(out.shape)\n",
        "        out = out.transpose(0, 1)#l*e\n",
        "        prob = self.generator(out[:, -1])#1*v\n",
        "        return prob"
      ],
      "outputs": [],
      "metadata": {
        "collapsed": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "During training, we need a subsequent word mask that will prevent model to look into\n",
        "the future words when making predictions. We will also need masks to hide\n",
        "source and target padding tokens. Below, let's define a function that will take care of both. \n",
        "\n",
        "\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "source": [
        "def generate_square_subsequent_mask(sz):\n",
        "    mask = (torch.triu(torch.ones((sz, sz), device=DEVICE)) == 1).transpose(0, 1)\n",
        "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
        "    return mask\n",
        "\n",
        "\n",
        "def create_mask(src, tgt):\n",
        "    src_seq_len = src.shape[0]\n",
        "    tgt_seq_len = tgt.shape[0]\n",
        "\n",
        "    tgt_mask = generate_square_subsequent_mask(tgt_seq_len)\n",
        "    src_mask = torch.zeros((src_seq_len, src_seq_len),device=DEVICE).type(torch.bool)\n",
        "\n",
        "    src_padding_mask = (src == PAD_IDX).transpose(0, 1)\n",
        "    tgt_padding_mask = (tgt == PAD_IDX).transpose(0, 1)\n",
        "    return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask"
      ],
      "outputs": [],
      "metadata": {
        "collapsed": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's now define the parameters of our model and instantiate the same. Below, we also \n",
        "define our loss function which is the cross-entropy loss and the optmizer used for training.\n",
        "\n",
        "\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "source": [
        "#from MyTransformer import Transformer\n",
        "#from transformer.Models import Transformer\n",
        "torch.manual_seed(seed)\n",
        "MAX_SEQ_LEN=1000\n",
        "SRC_VOCAB_SIZE = len(vocab_transform[SRC_LANGUAGE])\n",
        "TGT_VOCAB_SIZE = len(vocab_transform[TGT_LANGUAGE])\n",
        "EMB_SIZE = 512\n",
        "NHEAD = 8\n",
        "FFN_HID_DIM = 512\n",
        "NUM_LAYERS = 3\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "transformer = Seq2SeqTransformer(NUM_LAYERS, NUM_LAYERS, EMB_SIZE, NHEAD, SRC_VOCAB_SIZE, TGT_VOCAB_SIZE, FFN_HID_DIM)\n",
        "\n",
        "for p in transformer.parameters():\n",
        "    if p.dim() > 1:\n",
        "        nn.init.xavier_uniform_(p)\n",
        "\n",
        "transformer = transformer.to(DEVICE)\n",
        "\n",
        "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
        "\n",
        "optimizer = torch.optim.Adam(transformer.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)\n",
        "print(DEVICE)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "metadata": {
        "collapsed": false
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "source": [
        "# #from MyTransformer import Transformer\n",
        "# from transformer.Models import Transformer\n",
        "# torch.manual_seed(seed)\n",
        "# MAX_SEQ_LEN=1000\n",
        "# SRC_VOCAB_SIZE = len(vocab_transform[SRC_LANGUAGE])\n",
        "# TGT_VOCAB_SIZE = len(vocab_transform[TGT_LANGUAGE])\n",
        "# EMB_SIZE = 512\n",
        "# NHEAD = 8\n",
        "# FFN_HID_DIM = 1024\n",
        "# NUM_LAYERS = 3\n",
        "# DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# transformer=Transformer(\n",
        "#     n_src_vocab=SRC_VOCAB_SIZE,\n",
        "#     n_trg_vocab=TGT_VOCAB_SIZE,\n",
        "#     src_pad_idx=PAD_IDX,\n",
        "#     trg_pad_idx=PAD_IDX,\n",
        "#     trg_emb_prj_weight_sharing=True,\n",
        "#     emb_src_trg_weight_sharing=False,\n",
        "#     scale_emb_or_prj='emb'\n",
        "# )\n",
        "\n",
        "# transformer = transformer.to(DEVICE)\n",
        "\n",
        "# loss_fn = torch.nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
        "\n",
        "# optimizer = torch.optim.Adam(transformer.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)\n",
        "# print(DEVICE)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Collation\n",
        "---------\n",
        "\n",
        "As seen in the ``Data Sourcing and Processing`` section, our data iterator yields a pair of raw strings. \n",
        "We need to convert these string pairs into the batched tensors that can be processed by our ``Seq2Seq`` network \n",
        "defined previously. Below we define our collate function that convert batch of raw strings into batch tensors that\n",
        "can be fed directly into our model.   \n",
        "\n",
        "\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "# helper function to club together sequential operations\n",
        "def sequential_transforms(*transforms):\n",
        "    def func(txt_input):\n",
        "        for transform in transforms:\n",
        "            txt_input = transform(txt_input)\n",
        "        return txt_input\n",
        "    return func\n",
        "\n",
        "# function to add BOS/EOS and create tensor for input sequence indices\n",
        "def tensor_transform(token_ids: List[int]):\n",
        "    return torch.cat((torch.tensor([BOS_IDX]), \n",
        "                      torch.tensor(token_ids), \n",
        "                      torch.tensor([EOS_IDX])))\n",
        "\n",
        "# src and tgt language text transforms to convert raw strings into tensors indices\n",
        "text_transform = {}\n",
        "for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
        "    text_transform[ln] = sequential_transforms(token_transform[ln], #Tokenization\n",
        "                                               vocab_transform[ln], #Numericalization\n",
        "                                               tensor_transform) # Add BOS/EOS and create tensor\n",
        "\n",
        "\n",
        "# function to collate data samples into batch tesors\n",
        "def collate_fn(batch):\n",
        "    src_batch, tgt_batch = [], []\n",
        "    for src_sample, tgt_sample in batch:\n",
        "        src_batch.append(text_transform[SRC_LANGUAGE](src_sample.rstrip(\"\\n\")))\n",
        "        tgt_batch.append(text_transform[TGT_LANGUAGE](tgt_sample.rstrip(\"\\n\")))\n",
        "\n",
        "    src_batch = pad_sequence(src_batch, batch_first=True, padding_value=PAD_IDX)\n",
        "    tgt_batch = pad_sequence(tgt_batch, batch_first=True, padding_value=PAD_IDX)\n",
        "    return src_batch, tgt_batch"
      ],
      "outputs": [],
      "metadata": {
        "collapsed": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's define training and evaluation loop that will be called for each \n",
        "epoch.\n",
        "\n",
        "\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "BATCH_SIZE = 32\n",
        "def train_epoch(model, optimizer, epoch):\n",
        "    model.train()\n",
        "    losses = 0\n",
        "    train_iter = MyDataset(train_data)\n",
        "    train_dataloader = DataLoader(train_iter, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
        "    \n",
        "    for src, tgt in tqdm(train_dataloader, desc='Epoch: {}'.format(epoch)):\n",
        "        src = src.to(DEVICE)\n",
        "        tgt = tgt.to(DEVICE)\n",
        "        #print(tgt.shape)\n",
        "        #tgt_input = tgt[:-1, :]\n",
        "        tgt_input = tgt[:, :-1]\n",
        "\n",
        "        #src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
        "\n",
        "        #logits = model(src, tgt_input, src_mask, tgt_mask,src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
        "        logits=model(src,tgt_input)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        #tgt_out = tgt[1:, :]\n",
        "        tgt_out = tgt[:, 1:]\n",
        "        #loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
        "        #print(tgt_out.reshape(-1).shape,logits.shape)\n",
        "        loss = loss_fn(logits, tgt_out.reshape(-1))\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "        losses += loss.item()\n",
        "\n",
        "    return losses / len(train_dataloader)\n",
        "\n",
        "\n",
        "def evaluate(model):\n",
        "    model.eval()\n",
        "    losses = 0\n",
        "\n",
        "    val_iter = MyDataset(val_data)\n",
        "    val_dataloader = DataLoader(val_iter, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
        "\n",
        "    for src, tgt in tqdm(val_dataloader):\n",
        "        src = src.to(DEVICE)\n",
        "        tgt = tgt.to(DEVICE)\n",
        "        #tgt_input = tgt[:-1, :]\n",
        "        tgt_input = tgt[:, :-1]\n",
        "\n",
        "        #src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
        "\n",
        "        #logits = model(src, tgt_input, src_mask, tgt_mask,src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
        "        logits=model(src,tgt_input)\n",
        "        \n",
        "        #tgt_out = tgt[1:, :]\n",
        "        tgt_out = tgt[:, 1:]\n",
        "        #loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
        "        loss = loss_fn(logits, tgt_out.reshape(-1))\n",
        "        losses += loss.item()\n",
        "\n",
        "    return losses / len(val_dataloader)"
      ],
      "outputs": [],
      "metadata": {
        "collapsed": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we have all the ingredients to train our model. Let's do it!\n",
        "\n",
        "\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "source": [
        "# from timeit import default_timer as timer\n",
        "# NUM_EPOCHS = 20\n",
        "# best_loss=1e7\n",
        "# #BESTMODEL='./checkpoints/pytorch_bestmodel.pkl'\n",
        "# BESTMODEL='./checkpoints/test_bestmodel.pkl'\n",
        "# for epoch in range(1, NUM_EPOCHS+1):\n",
        "#     start_time = timer()\n",
        "#     train_loss = train_epoch(transformer, optimizer, epoch)\n",
        "#     end_time = timer()\n",
        "#     val_loss = evaluate(transformer)\n",
        "#     if val_loss<best_loss:\n",
        "#         best_loss=val_loss\n",
        "#         torch.save(transformer.state_dict(),BESTMODEL)\n",
        "#     print((f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f}, \"f\"Epoch time = {(end_time - start_time):.3f}s\"))\n",
        "\n"
      ],
      "outputs": [],
      "metadata": {
        "collapsed": false
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "source": [
        "# function to generate output sequence using greedy algorithm \n",
        "def greedy_decode(model, src, src_mask, max_len, start_symbol):\n",
        "    src = src.to(DEVICE)\n",
        "    src_mask=src_mask.to(DEVICE)\n",
        "\n",
        "    memory = model.encode(src, src_mask)\n",
        "    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(DEVICE)\n",
        "    for i in range(max_len-1):\n",
        "        memory = memory.to(DEVICE)\n",
        "        tgt_mask = (generate_square_subsequent_mask(ys.size(0)).type(torch.bool)).to(DEVICE)\n",
        "        out = model.decode(ys, memory, tgt_mask)\n",
        "        #print('out',out.shape)\n",
        "        out = out.transpose(0, 1)#l*e\n",
        "        prob = model.generator(out[:, -1])#1*v\n",
        "        _, next_word = torch.max(prob, dim=1)\n",
        "        next_word = next_word.item()\n",
        "\n",
        "        ys = torch.cat([ys,torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=0)\n",
        "        if next_word == EOS_IDX:\n",
        "            break\n",
        "    return ys\n",
        "\n",
        "\n",
        "# actual function to translate input sentence into target language\n",
        "def translate(model: torch.nn.Module, src_sentence: str):\n",
        "    model.eval()\n",
        "    src = text_transform[SRC_LANGUAGE](src_sentence).view(-1, 1)\n",
        "    num_tokens = src.shape[0]\n",
        "    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n",
        "    #print('src',src.shape)\n",
        "    tgt_tokens = greedy_decode(model,  src, src_mask, max_len=num_tokens + 10, start_symbol=BOS_IDX).flatten()\n",
        "    return \" \".join(vocab_transform[TGT_LANGUAGE].lookup_tokens(list(tgt_tokens.cpu().numpy()))).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\")"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "source": [
        "# # function to generate output sequence using greedy algorithm \n",
        "# def greedy_decode(model, src, max_len, start_symbol):\n",
        "#     src = src.to(DEVICE)\n",
        "\n",
        "#     memory = model.encode(src)\n",
        "#     ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(DEVICE)\n",
        "#     for i in range(max_len-1):\n",
        "#         memory = memory.to(DEVICE)\n",
        "#         out = model.decode(ys, memory)\n",
        "#         prob = model.trg_word_prj(out[:, -1])\n",
        "#         _, next_word = torch.max(prob, dim=1)\n",
        "#         next_word = next_word.item()\n",
        "\n",
        "#         ys = torch.cat([ys,torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=1)\n",
        "#         if next_word == EOS_IDX:\n",
        "#             break\n",
        "#     return ys\n",
        "\n",
        "\n",
        "# # actual function to translate input sentence into target language\n",
        "# def translate(model: torch.nn.Module, src_sentence: str):\n",
        "#     model.eval()\n",
        "#     src = text_transform[SRC_LANGUAGE](src_sentence).view(1, -1)#l*1\n",
        "#     num_tokens = src.shape[-1]\n",
        "#     tgt_tokens = greedy_decode(model,  src, max_len=num_tokens + 10, start_symbol=BOS_IDX).flatten()\n",
        "#     return \" \".join(vocab_transform[TGT_LANGUAGE].lookup_tokens(list(tgt_tokens.cpu().numpy()))).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\")"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "source": [
        "# BESTMODEL='./checkpoints/test_bestmodel.pkl'\n",
        "# transformer.load_state_dict(torch.load(BESTMODEL))\n",
        "# src=\" i like apple\"\n",
        "# print(translate(transformer, src))"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "source": [
        "#BESTMODEL='./checkpoints/my_bestmodel.pkl'\n",
        "BESTMODEL='./checkpoints/pytorch_bestmodel.pkl'\n",
        "transformer.load_state_dict(torch.load(BESTMODEL))\n",
        "src=\"I like apple\"\n",
        "print(translate(transformer, src))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 我 喜欢 苹果 \n"
          ]
        }
      ],
      "metadata": {
        "collapsed": false
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "source": [
        "src=\"I like apple\"\n",
        "src = text_transform[SRC_LANGUAGE](src).view(-1, 1).to(DEVICE)\n",
        "src=src.repeat(1,3)\n",
        "print(src.shape)\n",
        "tgt=torch.ones(1, 1).fill_(BOS_IDX).type(torch.long).to(DEVICE)\n",
        "tgt=tgt.repeat(1,3)\n",
        "transformer.predict(src, tgt).shape"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([5, 3])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 122260])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "source": [
        "x=torch.Tensor([1,3,4,5])\n",
        "print(x)\n",
        "y=torch.Tensor([0,1,1,0]).bool()\n",
        "x[y]"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 3., 4., 5.])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([3., 4.])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "source": [
        "def beam_search(model, inputs, topk, maxlen, min_ends=1, min_len=1):\n",
        "    \"\"\"\n",
        "    beam search解码\n",
        "    说明：这里的topk即beam size；\n",
        "    返回：最优解码序列。\n",
        "    \"\"\"\n",
        "    output_ids, output_scores = torch.full((1,1),BOS_IDX).to(DEVICE), torch.zeros(1,1).to(DEVICE)\n",
        "    for step in range(maxlen):\n",
        "        \n",
        "        scores= model.predict(inputs, output_ids)  # 计算当前得分\n",
        "        \n",
        "        if step == 0:  # 第1步预测后将输入重复topk次\n",
        "            inputs = inputs.repeat(1, topk)\n",
        "        scores = output_scores.reshape(-1,1) + scores  # 综合累积得分\n",
        "        \n",
        "        indices = torch.topk(scores.reshape(1,-1),topk,dim=1,largest=True)[1]  # 仅保留topk\n",
        "        \n",
        "        indices_1 = (indices // scores.shape[1]).squeeze()  # 行索引\n",
        "        indices_2 = indices % scores.shape[1] # 列索引\n",
        "        \n",
        "        output_ids = torch.cat([output_ids[:,indices_1], indices_2],dim=0)  # 更新输出\n",
        "        #print(output_ids)\n",
        "        output_scores = scores[indices_1,indices_2.squeeze()]\n",
        "        #print(output_scores)# 更新得分\n",
        "        is_end = output_ids[-1, :] == EOS_IDX  # 标记是否以end标记结束\n",
        "        end_counts = (output_ids == EOS_IDX).sum(0)  # 统计出现的end标记\n",
        "        #print(is_end.shape,end_counts.shape)\n",
        "        \n",
        "        if output_ids.shape[0] >= min_len:  # 最短长度判断\n",
        "            best = output_scores.argmax()  # 得分最大的那个\n",
        "            if is_end[best] and end_counts[best] >= min_ends:  # 如果已经终止\n",
        "                return output_ids[:,best]  # 直接输出\n",
        "            else:  # 否则，只保留未完成部分\n",
        "                flag = ~is_end | (end_counts < min_ends)  # 标记未完成序列\n",
        "                if not flag.all():  # 如果有已完成的\n",
        "                    inputs = inputs[:,flag] # 扔掉已完成序列\n",
        "                    output_ids = output_ids[:,flag]  # 扔掉已完成序列\n",
        "                    output_scores = output_scores[flag]  # 扔掉已完成序列\n",
        "                    end_counts = end_counts[flag]  # 扔掉已完成end计数\n",
        "                    topk = flag.sum()  # topk相应变化\n",
        "    # 达到长度直接输出\n",
        "    return output_ids[:,output_scores.argmax()]"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "source": [
        "def translate(model: torch.nn.Module, src_sentence: str):\n",
        "    model.eval()\n",
        "    src = text_transform[SRC_LANGUAGE](src_sentence).view(-1, 1).to(DEVICE)\n",
        "    num_tokens = src.shape[0]\n",
        "    tgt_tokens = beam_search(model,src,topk=3,maxlen=num_tokens+10)\n",
        "    return \" \".join(vocab_transform[TGT_LANGUAGE].lookup_tokens(list(tgt_tokens.cpu().numpy()))).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\")"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "source": [
        "#BESTMODEL='./checkpoints/my_bestmodel.pkl'\n",
        "BESTMODEL='./checkpoints/pytorch_bestmodel.pkl'\n",
        "transformer.load_state_dict(torch.load(BESTMODEL))\n",
        "src=\"I miss you.\"\n",
        "print(translate(transformer, src))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 我 忽略 了 你 。 \n"
          ]
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "References\n",
        "----------\n",
        "\n",
        "1. Attention is all you need paper.\n",
        "   https://papers.nips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf\n",
        "2. The annotated transformer. https://nlp.seas.harvard.edu/2018/04/03/attention.html#positional-encoding\n",
        "\n"
      ],
      "metadata": {}
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.6.13 64-bit ('torchhwk': conda)"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.13"
    },
    "interpreter": {
      "hash": "d21772f1c0845078982717cb0255994906cdfd11ac6285100cc8dcb63ba2f87f"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}